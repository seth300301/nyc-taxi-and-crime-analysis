{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e739678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6daf5e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = defaultdict()\n",
    "\n",
    "features['jan'] = pd.read_csv(\"../preprocessed_data/jan_data.csv\")\n",
    "features['feb'] = pd.read_csv(\"../preprocessed_data/feb_data.csv\")\n",
    "features['mar'] = pd.read_csv(\"../preprocessed_data/mar_data.csv\")\n",
    "features['apr'] = pd.read_csv(\"../preprocessed_data/apr_data.csv\")\n",
    "features['may'] = pd.read_csv(\"../preprocessed_data/may_data.csv\")\n",
    "features['jun'] = pd.read_csv(\"../preprocessed_data/jun_data.csv\")\n",
    "features['jul'] = pd.read_csv(\"../preprocessed_data/jul_data.csv\")\n",
    "features['aug'] = pd.read_csv(\"../preprocessed_data/aug_data.csv\")\n",
    "features['sep'] = pd.read_csv(\"../preprocessed_data/sep_data.csv\")\n",
    "features['oct'] = pd.read_csv(\"../preprocessed_data/oct_data.csv\")\n",
    "features['nov'] = pd.read_csv(\"../preprocessed_data/nov_data.csv\")\n",
    "features['dec'] = pd.read_csv(\"../preprocessed_data/dec_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c760d10",
   "metadata": {},
   "source": [
    "# Sorting Training (Jan-Sep) and Test (Oct-Dec) Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d6d247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the 6 exclusion zones (0, 103, 104, 110, 131, 137) as stated in Outlier Detection notebook\n",
    "exclusion_zones = [0,102,103,109,130,136]\n",
    "\n",
    "months = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(len(months)):\n",
    "    if (i < 9): # all months before October\n",
    "        features[months[i]] = features[months[i]].drop(labels = exclusion_zones)\n",
    "        train_data.append(features[months[i]])\n",
    "    else: # months from October onwards\n",
    "        features[months[i]] = features[months[i]].drop(labels = exclusion_zones)\n",
    "        test_data.append(features[months[i]])\n",
    "    \n",
    "train_set = pd.concat(train_data)\n",
    "train_set = train_set.reset_index()\n",
    "del train_set['index']\n",
    "\n",
    "test_set = pd.concat(test_data)\n",
    "test_set = test_set.reset_index()\n",
    "del test_set['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a97206",
   "metadata": {},
   "source": [
    "# 1st Attempt (Logistic Regression, Default Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baae0dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 - 100 pickups: 284 zones\n",
      "100 - 450 pickups: 262 zones\n",
      "450 - 850 pickups: 308 zones\n",
      "850 - 1550 pickups: 292 zones\n",
      "1550 - 3250 pickups: 283 zones\n",
      "3250 - 14000 pickups: 293 zones\n",
      "14000 - 90000 pickups: 298 zones\n",
      "90000 - 350000 pickups: 290 zones\n"
     ]
    }
   ],
   "source": [
    "# allocation bins with relatively equal frequency\n",
    "ranges = [-1, 100, 450, 850, 1550, 3250, 14000, 90000, 350000] # -1 to include zones with 0 pickups\n",
    "\n",
    "for i in range(len(ranges) - 1):\n",
    "    lower = ranges[i]\n",
    "    upper = ranges[i+1]\n",
    "    length = len(train_set['pickups'].loc[(train_set['pickups'] > lower) & (train_set['pickups'] < upper)])\n",
    "    print(str(lower) + ' - ' + str(upper) + ' pickups: ' + str(length) + ' zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff1c8830",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(\"pickups\", axis = 1)\n",
    "y_train = train_set['pickups']\n",
    "\n",
    "X_test = test_set.drop(\"pickups\", axis = 1)\n",
    "y_test = test_set['pickups']\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# assign pickup bin categories for both training and test labels\n",
    "\n",
    "new_y_train = []\n",
    "new_y_test = []\n",
    "\n",
    "for i in y_train:\n",
    "    if (i <= 100):\n",
    "        new_y_train.append(1)\n",
    "    elif ((i > 100) and (i <= 450)):\n",
    "        new_y_train.append(2)\n",
    "    elif ((i > 450) and (i <= 850)):\n",
    "        new_y_train.append(3)\n",
    "    elif ((i > 850) and (i <= 1550)):\n",
    "        new_y_train.append(4)\n",
    "    elif ((i > 1550) and (i <= 3250)):\n",
    "        new_y_train.append(5)\n",
    "    elif ((i > 3250) and (i <= 14000)):\n",
    "        new_y_train.append(6)\n",
    "    elif ((i > 14000) and (i <= 90000)):\n",
    "        new_y_train.append(7)\n",
    "    else:\n",
    "        new_y_train.append(8)\n",
    "\n",
    "for i in y_test:\n",
    "    if (i <= 100):\n",
    "        new_y_test.append(1)\n",
    "    elif ((i > 100) and (i <= 450)):\n",
    "        new_y_test.append(2)\n",
    "    elif ((i > 450) and (i <= 850)):\n",
    "        new_y_test.append(3)\n",
    "    elif ((i > 850) and (i <= 1550)):\n",
    "        new_y_test.append(4)\n",
    "    elif ((i > 1550) and (i <= 3250)):\n",
    "        new_y_test.append(5)\n",
    "    elif ((i > 3250) and (i <= 14000)):\n",
    "        new_y_test.append(6)\n",
    "    elif ((i > 14000) and (i <= 90000)):\n",
    "        new_y_test.append(7)\n",
    "    else:\n",
    "        new_y_test.append(8)\n",
    "\n",
    "y_train = np.array(new_y_train)\n",
    "y_test = np.array(new_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3449217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.3463035019455253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "acc = 0\n",
    "\n",
    "for i in range(10):\n",
    "    pred_y = []\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred_y.extend(clf.predict(X_test).tolist())\n",
    "\n",
    "    for i in range(len(pred_y)):\n",
    "        if (pred_y[i] == y_test[i]):\n",
    "            acc += 1\n",
    "        \n",
    "print(\"Logistic Regression Accuracy: \" + str(acc/(3*257*10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996104be",
   "metadata": {},
   "source": [
    "# 2nd Attempt (Logistic Regression, Optimal Parameter Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8809dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "{'C': 0.00026366508987303583, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "# use GridSearch to refine the model by finding the most suitable set of parameters for activation function \n",
    "# and solver method (takes awhile to run, wouldn't recommend)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'penalty' : ['none', 'l2'],\n",
    "               'C' : np.logspace(-4, 4, 20),\n",
    "               'solver' : ['sag', 'newton-cg', 'lbfgs', 'saga']}]\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), param_grid, cv = 10, scoring = 'accuracy')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af446cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6575875486381323\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty = 'l2', C= 0.00026366508987303583, solver = 'newton-cg', multi_class = 'multinomial')\n",
    "acc = 0\n",
    "\n",
    "for i in range(10):\n",
    "    pred_y = []\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred_y.extend(clf.predict(X_test).tolist())\n",
    "\n",
    "    for i in range(len(pred_y)):\n",
    "        if (pred_y[i] == y_test[i]):\n",
    "            acc += 1\n",
    "        \n",
    "print(\"Logistic Regression Accuracy: \" + str(acc/(3*257*10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8847748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Averaging Precision: 0.6759853431555487\n",
      "Micro Averaging Precision: 0.6575875486381323\n",
      "Weighted Averaging Precision: 0.670467628345071\n"
     ]
    }
   ],
   "source": [
    "# calculating the macro, micro, and weighted averaging for Precision\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "average = ['macro', 'micro', 'weighted']\n",
    "precisions = defaultdict()\n",
    "    \n",
    "for method in average:\n",
    "    result = precision_score(y_test, pred_y, average = method)\n",
    "    precisions[method] = result\n",
    "    print(method[0].upper() + method[1:] + \" Averaging Precision: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1152052f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Averaging Recall: 0.6769198969906156\n",
      "Micro Averaging Recall: 0.6575875486381323\n",
      "Weighted Averaging Recall: 0.6575875486381323\n"
     ]
    }
   ],
   "source": [
    "# calculating the macro, micro, and weighted averaging for Recall\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recalls = defaultdict()\n",
    "\n",
    "for method in average:\n",
    "    result = recall_score(y_test, pred_y, average = method)\n",
    "    recalls[method] = result\n",
    "    print(method[0].upper() + method[1:] + \" Averaging Recall: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a5e9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Averaging F1-Score: 0.6764522972896215\n",
      "Micro Averaging F1-Score: 0.6575875486381323\n",
      "Weighted Averaging F1-Score: 0.6639651300726548\n"
     ]
    }
   ],
   "source": [
    "# calculating the macro, micro, and weighted averaging for F1 Score\n",
    "for method in average:\n",
    "    result = (2*(precisions[method]*recalls[method])/(precisions[method]+recalls[method]))\n",
    "    print(method[0].upper() + method[1:] + \" Averaging F1-Score: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d849bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 17,  52,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,  64,  45,   0,   0,   0,   0,   0],\n",
       "       [  0,  10,  84,  16,   1,   0,   0,   0],\n",
       "       [  0,   0,  20,  36,  39,   4,   0,   0],\n",
       "       [  0,   0,   0,   0,  14,  81,   6,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,  80,   4],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,  93]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d7de1d",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09cd09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_set.drop(labels = ['pickups'], axis = 1)\n",
    "y_train = train_set['pickups']\n",
    "X_test = test_set.drop(labels = ['pickups'], axis = 1)\n",
    "y_test = test_set['pickups']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a52899b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.00026366508987303583, multi_class='multinomial',\n",
       "                   solver='newton-cg')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty = 'l2', C= 0.00026366508987303583, solver = 'newton-cg', multi_class = 'multinomial')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a47851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "refined_model = SelectFromModel(clf, prefit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9afd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_features = []\n",
    "for bool, feat in zip(refined_model.get_support(), list(X_train.columns.values)):\n",
    "    if bool:\n",
    "        refined_features.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9eb61d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a.num',\n",
       " 'a.p.age: 18-24',\n",
       " 'a.p.age: 25-44',\n",
       " 'a.p.age: 45-64',\n",
       " 'a.p.sex: M',\n",
       " 'a.p.sex: F',\n",
       " 'a.p.race: BLACK',\n",
       " 'a.p.race: WHITE',\n",
       " 'a.p.race: BLACK HISPANIC',\n",
       " 'a.p.race: WHITE HISPANIC',\n",
       " 'a.p.race: ASIAN / PACIFIC ISLANDER',\n",
       " 'a.law: F',\n",
       " 'a.law: M',\n",
       " 'c.num',\n",
       " 'average trip distance',\n",
       " 'credit payment',\n",
       " 'cash payment',\n",
       " 'no payment',\n",
       " 'dispute payment',\n",
       " 'average fare']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f16aac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using the new set of features deemed optimal by the SelectFromModel function\n",
    "X_train = train_set.filter(items = refined_features, axis = 1)\n",
    "X_test = test_set.filter(items = refined_features, axis = 1)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# assign pickup bin categories for both training and test labels\n",
    "\n",
    "new_y_train = []\n",
    "new_y_test = []\n",
    "\n",
    "for i in y_train:\n",
    "    if (i <= 100):\n",
    "        new_y_train.append(1)\n",
    "    elif ((i > 100) and (i <= 450)):\n",
    "        new_y_train.append(2)\n",
    "    elif ((i > 450) and (i <= 850)):\n",
    "        new_y_train.append(3)\n",
    "    elif ((i > 850) and (i <= 1550)):\n",
    "        new_y_train.append(4)\n",
    "    elif ((i > 1550) and (i <= 3250)):\n",
    "        new_y_train.append(5)\n",
    "    elif ((i > 3250) and (i <= 14000)):\n",
    "        new_y_train.append(6)\n",
    "    elif ((i > 14000) and (i <= 90000)):\n",
    "        new_y_train.append(7)\n",
    "    else:\n",
    "        new_y_train.append(8)\n",
    "\n",
    "for i in y_test:\n",
    "    if (i <= 100):\n",
    "        new_y_test.append(1)\n",
    "    elif ((i > 100) and (i <= 450)):\n",
    "        new_y_test.append(2)\n",
    "    elif ((i > 450) and (i <= 850)):\n",
    "        new_y_test.append(3)\n",
    "    elif ((i > 850) and (i <= 1550)):\n",
    "        new_y_test.append(4)\n",
    "    elif ((i > 1550) and (i <= 3250)):\n",
    "        new_y_test.append(5)\n",
    "    elif ((i > 3250) and (i <= 14000)):\n",
    "        new_y_test.append(6)\n",
    "    elif ((i > 14000) and (i <= 90000)):\n",
    "        new_y_test.append(7)\n",
    "    else:\n",
    "        new_y_test.append(8)\n",
    "\n",
    "y_train = np.array(new_y_train)\n",
    "y_test = np.array(new_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa80415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6562905317769131\n"
     ]
    }
   ],
   "source": [
    "# same model with only with the top features deemed useful by the SelectFromModel function\n",
    "clf = LogisticRegression(penalty = 'l2', C= 0.00026366508987303583, solver = 'newton-cg', multi_class = 'multinomial')\n",
    "acc = 0\n",
    "\n",
    "for i in range(10):\n",
    "    pred_y = []\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred_y.extend(clf.predict(X_test).tolist())\n",
    "\n",
    "    for i in range(len(pred_y)):\n",
    "        if (pred_y[i] == y_test[i]):\n",
    "            acc += 1\n",
    "        \n",
    "print(\"Logistic Regression Accuracy: \" + str(acc/(3*257*10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a914299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 17,  52,   1,   0,   0,   0,   0,   0],\n",
       "       [  0,  64,  45,   0,   0,   0,   0,   0],\n",
       "       [  0,  10,  84,  16,   1,   0,   0,   0],\n",
       "       [  0,   0,  20,  36,  39,   4,   0,   0],\n",
       "       [  0,   0,   0,   0,  14,  80,   7,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,  80,   4],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,  93]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83394624",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f4652ff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 - 50 pickups: 195 zones\n",
      "50 - 300 pickups: 219 zones\n",
      "300 - 775 pickups: 387 zones\n",
      "775 - 1750 pickups: 403 zones\n",
      "1750 - 5000 pickups: 332 zones\n",
      "5000 - 17000 pickups: 242 zones\n",
      "17000 - 100000 pickups: 262 zones\n",
      "100000 - 350000 pickups: 268 zones\n"
     ]
    }
   ],
   "source": [
    "# rearranging bin sizes again to provide more zones/data to bins 3,4, and 5\n",
    "ranges = [-1, 50, 300, 775, 1750, 5000, 17000, 100000, 350000] # -1 to include zones with 0 pickups\n",
    "\n",
    "for i in range(len(ranges) - 1):\n",
    "    lower = ranges[i]\n",
    "    upper = ranges[i+1]\n",
    "    length = len(train_set['pickups'].loc[(train_set['pickups'] > lower) & (train_set['pickups'] < upper)])\n",
    "    print(str(lower) + ' - ' + str(upper) + ' pickups: ' + str(length) + ' zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c12b7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only using the top features deemed useful by the SelectFromModel function\n",
    "X_train = train_set.filter(items = refined_features, axis = 1)\n",
    "X_test = test_set.filter(items = refined_features, axis = 1)\n",
    "y_train = train_set['pickups']\n",
    "y_test = test_set['pickups']\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# assign pickup bin categories for both training and test labels\n",
    "\n",
    "new_y_train = []\n",
    "new_y_test = []\n",
    "\n",
    "for i in y_train:\n",
    "    if (i <= 50):\n",
    "        new_y_train.append(1)\n",
    "    elif ((i > 50) and (i <= 300)):\n",
    "        new_y_train.append(2)\n",
    "    elif ((i > 300) and (i <= 775)):\n",
    "        new_y_train.append(3)\n",
    "    elif ((i > 775) and (i <= 1750)):\n",
    "        new_y_train.append(4)\n",
    "    elif ((i > 1750) and (i <= 5000)):\n",
    "        new_y_train.append(5)\n",
    "    elif ((i > 5000) and (i <= 17000)):\n",
    "        new_y_train.append(6)\n",
    "    elif ((i > 17000) and (i <= 100000)):\n",
    "        new_y_train.append(7)\n",
    "    else:\n",
    "        new_y_train.append(8)\n",
    "\n",
    "for i in y_test:\n",
    "    if (i <= 50):\n",
    "        new_y_test.append(1)\n",
    "    elif ((i > 50) and (i <= 300)):\n",
    "        new_y_test.append(2)\n",
    "    elif ((i > 300) and (i <= 775)):\n",
    "        new_y_test.append(3)\n",
    "    elif ((i > 775) and (i <= 1750)):\n",
    "        new_y_test.append(4)\n",
    "    elif ((i > 1750) and (i <= 5000)):\n",
    "        new_y_test.append(5)\n",
    "    elif ((i > 5000) and (i <= 17000)):\n",
    "        new_y_test.append(6)\n",
    "    elif ((i > 17000) and (i <= 100000)):\n",
    "        new_y_test.append(7)\n",
    "    else:\n",
    "        new_y_test.append(8)\n",
    "\n",
    "y_train = np.array(new_y_train)\n",
    "y_test = np.array(new_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d2d873a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7016861219195849\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty = 'l2', C= 0.00026366508987303583, solver = 'newton-cg', multi_class = 'multinomial')\n",
    "acc = 0\n",
    "\n",
    "for i in range(10):\n",
    "    pred_y = []\n",
    "\n",
    "    clf.fit(X_train,y_train)\n",
    "    pred_y.extend(clf.predict(X_test).tolist())\n",
    "\n",
    "    for i in range(len(pred_y)):\n",
    "        if (pred_y[i] == y_test[i]):\n",
    "            acc += 1\n",
    "        \n",
    "print(\"Logistic Regression Accuracy: \" + str(acc/(3*257*10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8fb7f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [11, 43,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 57, 82,  0,  0,  0,  0,  0],\n",
       "       [ 0,  3, 91, 42,  0,  0,  0,  0],\n",
       "       [ 0,  0, 11, 39, 69,  3,  0,  0],\n",
       "       [ 0,  0,  0,  0,  5, 70,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  7, 70,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 90]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac2d92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
